#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—É–±–ª–∏—á–Ω–æ–π –ø–∞–ø–∫–µ –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫–∞
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–ª–∞–¥–µ–ª—å—Ü–µ –ø–∞–ø–∫–∏ –∏ –µ—ë —Å–æ–¥–µ—Ä–∂–∏–º–æ–º
"""

import os
import re
import sys
import httpx
import json
from urllib.parse import unquote
from bs4 import BeautifulSoup
from dotenv import load_dotenv

load_dotenv()

def extract_folder_id(url):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç ID –ø–∞–ø–∫–∏ –∏–∑ URL"""
    match = re.search(r'/d/([^/?]+)', url)
    if match:
        return match.group(1)
    return None

def get_folder_info_via_api(folder_id, token=None):
    """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞–ø–∫–µ —á–µ—Ä–µ–∑ API –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫–∞"""
    if not token:
        token = os.getenv("YANDEX_DISK_TOKEN")
    
    if not token:
        return None, "–¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ YANDEX_DISK_TOKEN –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è."
    
    try:
        async def fetch_info():
            async with httpx.AsyncClient() as client:
                # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —á–µ—Ä–µ–∑ public API
                response = await client.get(
                    "https://cloud-api.yandex.net/v1/disk/public/resources",
                    params={"public_key": folder_id, "limit": 1000},
                    headers={"Authorization": f"OAuth {token}"},
                    timeout=30.0
                )
                return response
        
        import asyncio
        response = asyncio.run(fetch_info())
        
        if response.status_code == 200:
            data = response.json()
            return data, None
        else:
            return None, f"API –≤–µ—Ä–Ω—É–ª —Å—Ç–∞—Ç—É—Å {response.status_code}: {response.text}"
    except Exception as e:
        return None, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ API: {str(e)}"

def get_folder_info_via_html(url):
    """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞–ø–∫–µ —á–µ—Ä–µ–∑ –ø–∞—Ä—Å–∏–Ω–≥ HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
    try:
        async def fetch_html():
            async with httpx.AsyncClient() as client:
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                    'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7'
                }
                response = await client.get(url, headers=headers, timeout=30.0, follow_redirects=True)
                return response
        
        import asyncio
        response = asyncio.run(fetch_html())
        
        if response.status_code != 200:
            return None, f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É: {response.status_code}"
        
        html = response.text
        soup = BeautifulSoup(html, 'html.parser')
        
        info = {
            "folder_name": None,
            "owner": None,
            "owner_login": None,
            "created_date": None,
            "total_files": 0,
            "folders": [],
            "has_captcha": False,
            "raw_html_length": len(html)
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ CAPTCHA
        if "—Ä–æ–±–æ—Ç" in html.lower() or "captcha" in html.lower() or "smartcaptcha" in html.lower():
            info["has_captcha"] = True
            print("   ‚ö†Ô∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ CAPTCHA –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ")
        
        # –ò—â–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏
        title = soup.find('title')
        if title:
            title_text = title.get_text(strip=True)
            info["folder_name"] = title_text
            # –ï—Å–ª–∏ —ç—Ç–æ CAPTCHA, –Ω–∞–∑–≤–∞–Ω–∏–µ –±—É–¥–µ—Ç "–í—ã –Ω–µ —Ä–æ–±–æ—Ç?" –∏–ª–∏ –ø–æ–¥–æ–±–Ω–æ–µ
            if "—Ä–æ–±–æ—Ç" in title_text.lower():
                info["has_captcha"] = True
        
        # –ò—â–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–ª–∞–¥–µ–ª—å—Ü–µ
        # –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫ –æ–±—ã—á–Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤–ª–∞–¥–µ–ª—å—Ü–∞ –≤ –º–µ—Ç–∞-—Ç–µ–≥–∞—Ö –∏–ª–∏ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        meta_owner = soup.find('meta', attrs={'property': 'og:site_name'}) or soup.find('meta', attrs={'name': 'author'})
        if meta_owner:
            info["owner"] = meta_owner.get('content', '')
        
        # –ò—â–µ–º –≤ JSON-LD –∏–ª–∏ –¥—Ä—É–≥–∏—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        scripts = soup.find_all('script', type='application/ld+json')
        for script in scripts:
            try:
                data = json.loads(script.string)
                if isinstance(data, dict):
                    if 'author' in data:
                        info["owner"] = data.get('author', {}).get('name', '')
            except:
                pass
        
        # –ò—â–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ —Ç–µ–∫—Å—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        # –û–±—ã—á–Ω–æ –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç "–ü–∞–ø–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è [–∏–º—è]" –∏–ª–∏ –ø–æ–¥–æ–±–Ω–æ–µ
        page_text = soup.get_text()
        
        # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ç–∏–ø–∞ "–ü–∞–ø–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è", "–í–ª–∞–¥–µ–ª–µ—Ü" –∏ —Ç.–¥.
        owner_patterns = [
            r'–ü–∞–ø–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\s+([^\n\r]+)',
            r'–í–ª–∞–¥–µ–ª–µ—Ü[:\s]+([^\n\r]+)',
            r'–ê–≤—Ç–æ—Ä[:\s]+([^\n\r]+)',
            r'–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å[:\s]+([^\n\r]+)',
            r'([–ê-–Ø–∞-—èA-Za-z0-9_\-\.]+)\s+‚Äî\s+–Ø–Ω–¥–µ–∫—Å\s+–î–∏—Å–∫',  # –ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–µ—Ä–µ–¥ "‚Äî –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫"
        ]
        
        for pattern in owner_patterns:
            match = re.search(pattern, page_text, re.IGNORECASE)
            if match:
                owner_name = match.group(1).strip()
                # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∏–ª–∏ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                if len(owner_name) > 2 and owner_name not in ['–Ø–Ω–¥–µ–∫—Å', '–î–∏—Å–∫', '–ü–∞–ø–∫–∞']:
                    info["owner"] = owner_name
                    break
        
        # –ò—â–µ–º –≤ –º–µ—Ç–∞-—Ç–µ–≥–∞—Ö Open Graph
        og_title = soup.find('meta', attrs={'property': 'og:title'})
        if og_title:
            og_title_content = og_title.get('content', '')
            # –û–±—ã—á–Ω–æ —Ñ–æ—Ä–º–∞—Ç: "–ù–∞–∑–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏ ‚Äî –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫" –∏–ª–∏ "–ü–∞–ø–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ò–º—è"
            if '‚Äî' in og_title_content:
                parts = og_title_content.split('‚Äî')
                if len(parts) > 0:
                    potential_name = parts[0].strip()
                    if potential_name and len(potential_name) > 2:
                        info["folder_name"] = potential_name
            elif '–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è' in og_title_content.lower():
                match = re.search(r'–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\s+([^\s]+)', og_title_content, re.IGNORECASE)
                if match:
                    info["owner"] = match.group(1).strip()
        
        # –ò—â–µ–º –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (JSON-LD)
        scripts = soup.find_all('script', type='application/ld+json')
        for script in scripts:
            try:
                if script.string:
                    data = json.loads(script.string)
                    if isinstance(data, dict):
                        if 'author' in data:
                            author = data['author']
                            if isinstance(author, dict):
                                info["owner"] = author.get('name', '')
                            elif isinstance(author, str):
                                info["owner"] = author
                        if 'name' in data and not info["folder_name"]:
                            info["folder_name"] = data.get('name', '')
            except:
                pass
        
        # –ò—â–µ–º –≤ data-–∞—Ç—Ä–∏–±—É—Ç–∞—Ö
        elements_with_data = soup.find_all(attrs={'data-user': True})
        for elem in elements_with_data:
            user_data = elem.get('data-user')
            if user_data:
                try:
                    user_info = json.loads(user_data)
                    if isinstance(user_info, dict):
                        info["owner"] = user_info.get('name') or user_info.get('displayName') or user_info.get('login', '')
                        info["owner_login"] = user_info.get('login', '')
                except:
                    info["owner"] = user_data
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã –∏ –ø–∞–ø–∫–∏
        links = soup.find_all('a', href=True)
        folders_found = set()
        files_count = 0
        
        for link in links:
            href = link.get('href', '')
            text = link.get_text(strip=True)
            
            # –ò—â–µ–º –ø–∞–ø–∫–∏ (–æ–±—ã—á–Ω–æ –∏–º–µ—é—Ç –ø—Ä–µ—Ñ–∏–∫—Å + –∏–ª–∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Å)
            if '+' in text or 'folder' in href.lower() or 'dir' in href.lower():
                folder_name = text.replace('+', '').strip()
                if folder_name and folder_name not in folders_found:
                    folders_found.add(folder_name)
                    info["folders"].append(folder_name)
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã
            if any(ext in text.lower() for ext in ['.jpg', '.jpeg', '.png', '.gif', '.pdf', '.doc']):
                files_count += 1
        
        info["total_files"] = files_count
        
        # –ò—â–µ–º –¥–∞—Ç—É —Å–æ–∑–¥–∞–Ω–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å)
        date_patterns = [
            r'(\d{2}\.\d{2}\.\d{4})',
            r'(\d{4}-\d{2}-\d{2})',
        ]
        
        for pattern in date_patterns:
            match = re.search(pattern, page_text)
            if match:
                info["created_date"] = match.group(1)
                break
        
        return info, None
        
    except Exception as e:
        return None, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ HTML: {str(e)}"

def main():
    url = "https://disk.yandex.ru/d/kXWj5qy7vdZwXA"
    
    if len(sys.argv) > 1:
        url = sys.argv[1]
    
    print("=" * 60)
    print("–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–∞–ø–∫–µ –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫–∞")
    print("=" * 60)
    print(f"URL: {url}\n")
    
    folder_id = extract_folder_id(url)
    if not folder_id:
        print("‚ùå –û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å ID –ø–∞–ø–∫–∏ –∏–∑ URL")
        print("–û–∂–∏–¥–∞–µ—Ç—Å—è —Ñ–æ—Ä–º–∞—Ç: https://disk.yandex.ru/d/ID")
        sys.exit(1)
    
    print(f"üìÅ ID –ø–∞–ø–∫–∏: {folder_id}\n")
    
    # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —á–µ—Ä–µ–∑ API
    print("üîç –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ API...")
    api_data, api_error = get_folder_info_via_api(folder_id)
    
    if api_data:
        print("‚úÖ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∞ —á–µ—Ä–µ–∑ API:")
        print(f"   –ù–∞–∑–≤–∞–Ω–∏–µ: {api_data.get('name', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}")
        print(f"   –ü—É—Ç—å: {api_data.get('path', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}")
        print(f"   –¢–∏–ø: {api_data.get('type', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}")
        print(f"   –†–∞–∑–º–µ—Ä: {api_data.get('size', 0)} –±–∞–π—Ç")
        
        if 'created' in api_data:
            print(f"   –°–æ–∑–¥–∞–Ω–æ: {api_data['created']}")
        if 'modified' in api_data:
            print(f"   –ò–∑–º–µ–Ω–µ–Ω–æ: {api_data['modified']}")
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–ª–∞–¥–µ–ª—å—Ü–µ (–µ—Å–ª–∏ –µ—Å—Ç—å –≤ –æ—Ç–≤–µ—Ç–µ)
        if 'owner' in api_data:
            owner = api_data['owner']
            print(f"   –í–ª–∞–¥–µ–ª–µ—Ü: {owner.get('display_name', owner.get('login', '–ù–µ —É–∫–∞–∑–∞–Ω–æ'))}")
            print(f"   –õ–æ–≥–∏–Ω: {owner.get('login', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}")
        
        # –°–ø–∏—Å–æ–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        items = api_data.get('_embedded', {}).get('items', [])
        if items:
            print(f"\n   –°–æ–¥–µ—Ä–∂–∏–º–æ–µ ({len(items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤):")
            folders = [item for item in items if item.get('type') == 'dir']
            files = [item for item in items if item.get('type') == 'file']
            print(f"   - –ü–∞–ø–æ–∫: {len(folders)}")
            print(f"   - –§–∞–π–ª–æ–≤: {len(files)}")
            
            if folders:
                print("\n   –ü–∞–ø–∫–∏:")
                for folder in folders[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                    print(f"     üìÅ {folder.get('name', '–ë–µ–∑ –∏–º–µ–Ω–∏')}")
    else:
        print(f"‚ö†Ô∏è  API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {api_error}")
    
    print("\n" + "-" * 60)
    print("üîç –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ –ø–∞—Ä—Å–∏–Ω–≥ HTML...")
    
    # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —á–µ—Ä–µ–∑ –ø–∞—Ä—Å–∏–Ω–≥ HTML
    html_info, html_error = get_folder_info_via_html(url)
    
    if html_info:
        print("‚úÖ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∞ —á–µ—Ä–µ–∑ HTML:")
        
        if html_info.get("has_captcha"):
            print("   ‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ CAPTCHA!")
            print("   –≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –Ø–Ω–¥–µ–∫—Å –±–ª–æ–∫–∏—Ä—É–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –¥–æ—Å—Ç—É–ø.")
            print("   –î–ª—è –ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ—Ç–∫—Ä–æ–π—Ç–µ URL –≤ –±—Ä–∞—É–∑–µ—Ä–µ –≤—Ä—É—á–Ω—É—é.\n")
        
        if html_info.get("folder_name") and not html_info.get("has_captcha"):
            print(f"   –ù–∞–∑–≤–∞–Ω–∏–µ: {html_info['folder_name']}")
        elif html_info.get("folder_name"):
            print(f"   –ù–∞–∑–≤–∞–Ω–∏–µ (–≤–æ–∑–º–æ–∂–Ω–æ –Ω–µ—Ç–æ—á–Ω–æ–µ –∏–∑-–∑–∞ CAPTCHA): {html_info['folder_name']}")
        
        if html_info.get("owner"):
            print(f"   –í–ª–∞–¥–µ–ª–µ—Ü: {html_info['owner']}")
        if html_info.get("owner_login"):
            print(f"   –õ–æ–≥–∏–Ω: {html_info['owner_login']}")
        if html_info.get("created_date"):
            print(f"   –î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: {html_info['created_date']}")
        
        if not html_info.get("has_captcha"):
            if html_info.get("folders"):
                print(f"\n   –ù–∞–π–¥–µ–Ω–æ –ø–∞–ø–æ–∫: {len(html_info['folders'])}")
                for folder in html_info['folders'][:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                    print(f"     üìÅ {folder}")
            if html_info.get("total_files") > 0:
                print(f"   –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {html_info['total_files']}")
        
        print(f"\n   –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:")
        print(f"   –†–∞–∑–º–µ—Ä HTML: {html_info.get('raw_html_length', 0)} –±–∞–π—Ç")
        
    else:
        print(f"‚ö†Ô∏è  HTML –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è: {html_error}")
    
    print("\n" + "=" * 60)
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    if html_info and html_info.get("has_captcha"):
        print("\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
        print("   –Ø–Ω–¥–µ–∫—Å –±–ª–æ–∫–∏—Ä—É–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –¥–æ—Å—Ç—É–ø –∫ —ç—Ç–æ–π –ø–∞–ø–∫–µ —á–µ—Ä–µ–∑ CAPTCHA.")
        print("   –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏:")
        print("   1. –û—Ç–∫—Ä–æ–π—Ç–µ URL –≤ –±—Ä–∞—É–∑–µ—Ä–µ –≤—Ä—É—á–Ω—É—é")
        print("   2. –ü—Ä–æ–π–¥–∏—Ç–µ –ø—Ä–æ–≤–µ—Ä–∫—É CAPTCHA")
        print("   3. –ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –≤—ã —É–≤–∏–¥–∏—Ç–µ:")
        print("      - –ù–∞–∑–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏")
        print("      - –ò–º—è –≤–ª–∞–¥–µ–ª—å—Ü–∞ (–æ–±—ã—á–Ω–æ –≤–≤–µ—Ä—Ö—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã)")
        print("      - –°–ø–∏—Å–æ–∫ –ø–∞–ø–æ–∫ –∏ —Ñ–∞–π–ª–æ–≤")
        print("\n   –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ:")
        print("   - –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å YANDEX_DISK_TOKEN –≤–ª–∞–¥–µ–ª—å—Ü–∞ –ø–∞–ø–∫–∏,")
        print("     –≤—ã –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å API –¥–ª—è –¥–æ—Å—Ç—É–ø–∞")
        print("   - –ò–ª–∏ –ø–æ–ø—Ä–æ—Å–∏—Ç–µ –≤–ª–∞–¥–µ–ª—å—Ü–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –ø–∞–ø–∫–µ")
    
    print("\n" + "=" * 60)
    print("–ì–æ—Ç–æ–≤–æ!")
    print("=" * 60)

if __name__ == "__main__":
    main()

